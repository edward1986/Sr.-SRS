name: Blog Generation with Ollama

on:
  push:
    branches:
      - main
  pull_request:
    branches:
      - main

jobs:
  blog-generation:
    runs-on: ubuntu-latest

    steps:
    - name: Checkout Repository
      uses: actions/checkout@v3

    - name: Install System Dependencies
      run: |
        sudo apt-get clean
        sudo rm -rf /var/lib/apt/lists/*
        sudo apt-get update
        sudo apt-get install -y ttf-mscorefonts-installer imagemagick ghostscript curl jq

    - name: Install Ollama
      run: |
        echo "Installing Ollama CLI..."
        curl -fsSL https://ollama.com/install.sh | sh
        ollama --version

    - name: Start Ollama Service
      run: |
        echo "Starting Ollama service..."
        ollama serve &
        sleep 5  # Allow time for the service to initialize

    - name: Verify Ollama Service
      run: |
        echo "Checking if Ollama API is running..."
        curl http://127.0.0.1:11434/ || (echo "Ollama service not responding" && exit 1)

    - name: Pull LLaMA Model
      run: |
        echo "Pulling the LLaMA 2 model..."
        if ! ollama pull llama2; then
          echo "Model pull failed. Please check model availability or permissions."
          exit 1
        fi

    - name: Generate Blog
      run: |
        echo "Generating the blog content..."
        python blog_generator.py

    - name: Verify Generated Blog File
      run: |
        echo "Checking for the generated blog file..."
        if [ ! -f "generated_blog.txt" ]; then
          echo "Error: generated_blog.txt not found."
          exit 1
        fi
        echo "Generated blog file verified."

    - name: Upload Generated Blog
      uses: actions/upload-artifact@v3
      with:
        name: Generated-Blog
        path: generated_blog.txt
